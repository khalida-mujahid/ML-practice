{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "batch9_lecture11.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khalida-mujahid/ML-practice/blob/master/batch9_lecture11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_RYymq-l-iN",
        "colab_type": "code",
        "outputId": "7fc8efa2-6a55-4419-94c0-1b9a8b11bea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Mar  1 14:13:54 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 410.79       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egAZB7abmqN3",
        "colab_type": "code",
        "outputId": "bdab4b76-31cb-4d39-95c7-c1b811a4d686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras.datasets import boston_housing\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICvlJKDFm5gZ",
        "colab_type": "code",
        "outputId": "18a8c1d9-32c9-4309-ede5-a1e7c9e00eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 13)\n",
            "(404,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrmtN9hUm98Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWwFW5G7nDjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(2, activation = 'relu', use_bias= False, ))\n",
        "model.add(Dense(1, use_bias= False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5sFp1GWoLdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'adam', loss = 'mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98RNBoAtsmBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K34XqJ3xsq6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor = 'val_loss', patience = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLup-Ec4owI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x = x_train, y = y_train, batch_size = 32, epochs = 10000, \n",
        "         validation_split = 0.2, callbacks = [es])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMHzKppWqAik",
        "colab_type": "code",
        "outputId": "05cf6df8-6c65-4f0b-b32d-29e43f06644c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(x = x_test, y = y_test, batch_size = 32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 112us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "615.8578574984681"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWig-Ju4t5h5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIUtEW9TuXIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WTmOhhE6lS3",
        "colab_type": "code",
        "outputId": "7b08caee-fd01-44c9-9097-f66342f2f9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "103JsZZv6peG",
        "colab_type": "code",
        "outputId": "bff99a11-8852-4937-e637-49c6e35630be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_train[:4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 0 0 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvFPOua06xnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlG8hP5U69cc",
        "colab_type": "code",
        "outputId": "9859d085-91b6-4810-8100-cbfd942ed1de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "plt.figure(figsize = (15,15))\n",
        "for i in range(5):\n",
        "  idx = np.random.randint(0, 60000)\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.imshow(x_train[idx])\n",
        "  plt.axis('off')\n",
        "  plt.title(y_train[idx])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA18AAAI+CAYAAABDmbAiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNCucJF0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x1080 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrDBCpML7ogi",
        "colab_type": "code",
        "outputId": "26a9bda0-f75d-4be7-d904-3f024182e1cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train = x_train.reshape(-1, 28*28)\n",
        "print(x_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lei2JpF8UAj",
        "colab_type": "code",
        "outputId": "8f076696-9087-4068-a366-7572c9cafa25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test = x_test.reshape(-1, 28*28)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mCFyoi9-jco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmEL834P8ZpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Activation, Average"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR2m3aMw8hrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = Input(shape = (784, ))\n",
        "\n",
        "x1 = Dense(256, activation = 'tanh')(inp)\n",
        "x2 = Dense(128, activation = 'tanh')(inp)\n",
        "x3 = Dense(512, activation = 'tanh')(inp)\n",
        "\n",
        "x1 = Dense(10, activation = 'sigmoid')(x1)\n",
        "x2 = Dense(10, activation = 'sigmoid')(x2)\n",
        "x3 = Dense(10, activation = 'sigmoid')(x3)\n",
        "\n",
        "x = Average()([x1,x2,x3])\n",
        "out = Dense(10, activation = 'softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOTst6hR9YsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inp, out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qCJ5laI9hKJ",
        "colab_type": "code",
        "outputId": "5cc40ccc-4c28-47ef-8a54-51850aa22e8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           (None, 784)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_56 (Dense)                (None, 256)          200960      input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_57 (Dense)                (None, 128)          100480      input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_58 (Dense)                (None, 512)          401920      input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_59 (Dense)                (None, 10)           2570        dense_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_60 (Dense)                (None, 10)           1290        dense_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_61 (Dense)                (None, 10)           5130        dense_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_8 (Average)             (None, 10)           0           dense_59[0][0]                   \n",
            "                                                                 dense_60[0][0]                   \n",
            "                                                                 dense_61[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_62 (Dense)                (None, 10)           110         average_8[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 712,460\n",
            "Trainable params: 712,460\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHVDAfOM9iUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mjE-1d_-uxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy',\n",
        "             optimizer = 'adam',\n",
        "             metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A5Z3Exl-pl2",
        "colab_type": "code",
        "outputId": "ccba40ea-e975-4d2e-8f4e-2d9ffaedddec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1853
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs = 1000, validation_split = 0.2, \n",
        "          callbacks = [es])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/1000\n",
            "48000/48000 [==============================] - 13s 269us/step - loss: 1.2790 - acc: 0.6446 - val_loss: 0.9221 - val_acc: 0.7112\n",
            "Epoch 2/1000\n",
            "48000/48000 [==============================] - 12s 253us/step - loss: 0.8471 - acc: 0.7060 - val_loss: 0.7784 - val_acc: 0.7222\n",
            "Epoch 3/1000\n",
            "48000/48000 [==============================] - 12s 253us/step - loss: 0.7662 - acc: 0.7159 - val_loss: 0.7284 - val_acc: 0.7242\n",
            "Epoch 4/1000\n",
            "48000/48000 [==============================] - 12s 259us/step - loss: 0.7316 - acc: 0.7205 - val_loss: 0.6985 - val_acc: 0.7290\n",
            "Epoch 5/1000\n",
            "48000/48000 [==============================] - 12s 257us/step - loss: 0.7234 - acc: 0.7209 - val_loss: 0.7069 - val_acc: 0.7163\n",
            "Epoch 6/1000\n",
            "48000/48000 [==============================] - 12s 249us/step - loss: 0.7192 - acc: 0.7154 - val_loss: 0.7151 - val_acc: 0.7148\n",
            "Epoch 7/1000\n",
            "48000/48000 [==============================] - 12s 247us/step - loss: 0.7001 - acc: 0.7282 - val_loss: 0.6885 - val_acc: 0.7283\n",
            "Epoch 8/1000\n",
            "48000/48000 [==============================] - 12s 247us/step - loss: 0.6976 - acc: 0.7315 - val_loss: 0.7238 - val_acc: 0.7428\n",
            "Epoch 9/1000\n",
            "48000/48000 [==============================] - 12s 249us/step - loss: 0.7049 - acc: 0.7311 - val_loss: 0.6994 - val_acc: 0.7383\n",
            "Epoch 10/1000\n",
            "48000/48000 [==============================] - 12s 247us/step - loss: 0.6972 - acc: 0.7304 - val_loss: 0.7165 - val_acc: 0.7233\n",
            "Epoch 11/1000\n",
            "48000/48000 [==============================] - 12s 251us/step - loss: 0.7024 - acc: 0.7261 - val_loss: 0.7033 - val_acc: 0.7192\n",
            "Epoch 12/1000\n",
            "48000/48000 [==============================] - 12s 255us/step - loss: 0.6786 - acc: 0.7365 - val_loss: 0.6651 - val_acc: 0.7457\n",
            "Epoch 13/1000\n",
            "48000/48000 [==============================] - 12s 257us/step - loss: 0.6653 - acc: 0.7428 - val_loss: 0.6471 - val_acc: 0.7533\n",
            "Epoch 14/1000\n",
            "48000/48000 [==============================] - 12s 256us/step - loss: 0.6655 - acc: 0.7420 - val_loss: 0.6604 - val_acc: 0.7355\n",
            "Epoch 15/1000\n",
            "48000/48000 [==============================] - 12s 254us/step - loss: 0.6658 - acc: 0.7347 - val_loss: 0.6514 - val_acc: 0.7536\n",
            "Epoch 16/1000\n",
            "48000/48000 [==============================] - 12s 253us/step - loss: 0.6652 - acc: 0.7398 - val_loss: 0.6656 - val_acc: 0.7301\n",
            "Epoch 17/1000\n",
            "48000/48000 [==============================] - 12s 253us/step - loss: 0.6572 - acc: 0.7407 - val_loss: 0.6683 - val_acc: 0.7228\n",
            "Epoch 18/1000\n",
            "48000/48000 [==============================] - 12s 251us/step - loss: 0.6498 - acc: 0.7358 - val_loss: 0.6371 - val_acc: 0.7505\n",
            "Epoch 19/1000\n",
            "48000/48000 [==============================] - 12s 251us/step - loss: 0.6394 - acc: 0.7535 - val_loss: 0.6353 - val_acc: 0.7625\n",
            "Epoch 20/1000\n",
            "48000/48000 [==============================] - 12s 250us/step - loss: 0.6360 - acc: 0.7506 - val_loss: 0.6425 - val_acc: 0.7487\n",
            "Epoch 21/1000\n",
            "48000/48000 [==============================] - 12s 253us/step - loss: 0.6370 - acc: 0.7563 - val_loss: 0.6386 - val_acc: 0.7546\n",
            "Epoch 22/1000\n",
            "48000/48000 [==============================] - 12s 249us/step - loss: 0.6403 - acc: 0.7530 - val_loss: 0.6512 - val_acc: 0.7583\n",
            "Epoch 23/1000\n",
            "48000/48000 [==============================] - 12s 249us/step - loss: 0.6569 - acc: 0.7398 - val_loss: 0.6371 - val_acc: 0.7535\n",
            "Epoch 24/1000\n",
            "48000/48000 [==============================] - 12s 253us/step - loss: 0.6429 - acc: 0.7482 - val_loss: 0.6517 - val_acc: 0.7268\n",
            "Epoch 25/1000\n",
            "48000/48000 [==============================] - 12s 252us/step - loss: 0.6422 - acc: 0.7384 - val_loss: 0.6529 - val_acc: 0.7384\n",
            "Epoch 26/1000\n",
            "48000/48000 [==============================] - 12s 251us/step - loss: 0.6432 - acc: 0.7480 - val_loss: 0.6344 - val_acc: 0.7518\n",
            "Epoch 27/1000\n",
            "48000/48000 [==============================] - 12s 252us/step - loss: 0.6537 - acc: 0.7394 - val_loss: 0.6478 - val_acc: 0.7393\n",
            "Epoch 28/1000\n",
            "48000/48000 [==============================] - 12s 252us/step - loss: 0.6524 - acc: 0.7445 - val_loss: 0.6397 - val_acc: 0.7558\n",
            "Epoch 29/1000\n",
            "48000/48000 [==============================] - 12s 254us/step - loss: 0.6502 - acc: 0.7439 - val_loss: 0.6575 - val_acc: 0.7298\n",
            "Epoch 30/1000\n",
            "48000/48000 [==============================] - 12s 258us/step - loss: 0.6447 - acc: 0.7464 - val_loss: 0.6430 - val_acc: 0.7492\n",
            "Epoch 31/1000\n",
            "48000/48000 [==============================] - 12s 260us/step - loss: 0.6397 - acc: 0.7522 - val_loss: 0.6354 - val_acc: 0.7505\n",
            "Epoch 32/1000\n",
            "48000/48000 [==============================] - 12s 256us/step - loss: 0.6287 - acc: 0.7574 - val_loss: 0.6137 - val_acc: 0.7639\n",
            "Epoch 33/1000\n",
            "48000/48000 [==============================] - 12s 257us/step - loss: 0.6233 - acc: 0.7593 - val_loss: 0.6151 - val_acc: 0.7784\n",
            "Epoch 34/1000\n",
            "48000/48000 [==============================] - 12s 259us/step - loss: 0.6270 - acc: 0.7567 - val_loss: 0.6629 - val_acc: 0.7462\n",
            "Epoch 35/1000\n",
            "48000/48000 [==============================] - 12s 256us/step - loss: 0.6356 - acc: 0.7512 - val_loss: 0.6551 - val_acc: 0.7439\n",
            "Epoch 36/1000\n",
            "48000/48000 [==============================] - 12s 256us/step - loss: 0.6344 - acc: 0.7534 - val_loss: 0.6357 - val_acc: 0.7652\n",
            "Epoch 37/1000\n",
            "48000/48000 [==============================] - 12s 257us/step - loss: 0.6160 - acc: 0.7625 - val_loss: 0.6217 - val_acc: 0.7586\n",
            "Epoch 38/1000\n",
            "48000/48000 [==============================] - 12s 255us/step - loss: 0.6108 - acc: 0.7684 - val_loss: 0.6038 - val_acc: 0.7801\n",
            "Epoch 39/1000\n",
            "48000/48000 [==============================] - 12s 250us/step - loss: 0.6052 - acc: 0.7752 - val_loss: 0.6105 - val_acc: 0.7758\n",
            "Epoch 40/1000\n",
            "48000/48000 [==============================] - 12s 248us/step - loss: 0.6180 - acc: 0.7691 - val_loss: 0.6323 - val_acc: 0.7688\n",
            "Epoch 41/1000\n",
            "48000/48000 [==============================] - 12s 250us/step - loss: 0.6155 - acc: 0.7688 - val_loss: 0.6259 - val_acc: 0.7731\n",
            "Epoch 42/1000\n",
            "48000/48000 [==============================] - 12s 249us/step - loss: 0.6134 - acc: 0.7714 - val_loss: 0.6195 - val_acc: 0.7704\n",
            "Epoch 43/1000\n",
            "48000/48000 [==============================] - 12s 249us/step - loss: 0.6100 - acc: 0.7692 - val_loss: 0.5965 - val_acc: 0.7745\n",
            "Epoch 44/1000\n",
            "48000/48000 [==============================] - 12s 247us/step - loss: 0.6074 - acc: 0.7749 - val_loss: 0.6195 - val_acc: 0.7667\n",
            "Epoch 45/1000\n",
            "48000/48000 [==============================] - 12s 248us/step - loss: 0.6091 - acc: 0.7665 - val_loss: 0.6015 - val_acc: 0.7758\n",
            "Epoch 46/1000\n",
            "48000/48000 [==============================] - 12s 249us/step - loss: 0.6135 - acc: 0.7654 - val_loss: 0.5982 - val_acc: 0.7780\n",
            "Epoch 47/1000\n",
            "48000/48000 [==============================] - 12s 249us/step - loss: 0.5924 - acc: 0.7769 - val_loss: 0.6106 - val_acc: 0.7787\n",
            "Epoch 48/1000\n",
            "48000/48000 [==============================] - 12s 253us/step - loss: 0.5999 - acc: 0.7803 - val_loss: 0.6030 - val_acc: 0.7835\n",
            "Epoch 49/1000\n",
            "48000/48000 [==============================] - 13s 260us/step - loss: 0.6215 - acc: 0.7649 - val_loss: 0.6174 - val_acc: 0.7692\n",
            "Epoch 50/1000\n",
            "48000/48000 [==============================] - 13s 263us/step - loss: 0.6246 - acc: 0.7659 - val_loss: 0.6223 - val_acc: 0.7642\n",
            "Epoch 51/1000\n",
            "48000/48000 [==============================] - 13s 264us/step - loss: 0.6163 - acc: 0.7701 - val_loss: 0.6359 - val_acc: 0.7730\n",
            "Epoch 52/1000\n",
            "48000/48000 [==============================] - 12s 259us/step - loss: 0.6121 - acc: 0.7719 - val_loss: 0.6199 - val_acc: 0.7671\n",
            "Epoch 53/1000\n",
            "48000/48000 [==============================] - 12s 260us/step - loss: 0.6232 - acc: 0.7623 - val_loss: 0.6536 - val_acc: 0.7367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2d7ee87748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-M43p8FdOuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}